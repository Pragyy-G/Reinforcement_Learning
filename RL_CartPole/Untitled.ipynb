{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c742d42",
   "metadata": {},
   "source": [
    "## 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf969ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06572a65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed51f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404c6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d83d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "184a74e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvirtualdisplay in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.2.5)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: EasyProcess in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pyvirtualdisplay) (1.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opencv-python) (1.22.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvirtualdisplay opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6822f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4d23c",
   "metadata": {},
   "source": [
    "## 2. Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e046290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'CartPole-v1'\n",
    "env = gym.make(environment_name, render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd9c2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CartPole-v1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8905a8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64f0a3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:20.0\n",
      "Episode:2 Score:22.0\n",
      "Episode:3 Score:14.0\n",
      "Episode:4 Score:19.0\n",
      "Episode:5 Score:57.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"rl_simulation.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter('rl_simulation.mp4', fourcc, 24.0, (600, 400))\n",
    "\n",
    "for episode in range(1,episodes +1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render() #Allows us to view the grpahical representaation of environment\n",
    "        time.sleep(0.1)\n",
    "        # Render the environment\n",
    "        frame = env.render()\n",
    "        # Check if the frame is not empty\n",
    "        if frame is not None and frame.shape[0] > 0 and frame.shape[1] > 0:\n",
    "            frame = cv2.resize(frame, (600, 400))\n",
    "\n",
    "        # Write the frame to the video\n",
    "        video_writer.write(frame)\n",
    "\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done,truncated, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "\n",
    "# Release the video writer\n",
    "video_writer.release()\n",
    "\n",
    "# Display the video\n",
    "Video(\"rl_simulation.mp4\")\n",
    "#env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9b2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b81eb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01080834, -0.0189237 , -0.04048218, -0.03012205], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25f8ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d62874c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17ea7c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.03137867,  0.04174085, -0.03695783,  0.00263751], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e9244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76d94fc8",
   "metadata": {},
   "source": [
    "## 3. Understanding Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b90e205c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f77f241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6d747f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.6895094e+00,  2.3753533e+38, -1.6085929e-01, -1.2720713e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observation space\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fbc32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c5bc5b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "215b5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece83e22",
   "metadata": {},
   "source": [
    "### Train a RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06ebc2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are looking for Model Free based Learning since it can be used to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02e57dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the directories\n",
    "log_path = os.path.join('Training','Logs' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60e06b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Logs'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3b2682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment_name, render_mode='human')\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b52a72ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\asus\\anaconda3\\lib\\site-packages (0.16.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (2022.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28384763",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_24\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 36   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 56   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008762405 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.00736     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.59        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 50.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012022843 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.668      |\n",
      "|    explained_variance   | 0.0949      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 34.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008889707 |\n",
      "|    clip_fraction        | 0.0782      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 242          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085113365 |\n",
      "|    clip_fraction        | 0.0881       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.619       |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.6         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0167      |\n",
      "|    value_loss           | 57.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010074887 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.6        |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004740895 |\n",
      "|    clip_fraction        | 0.0319      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.584      |\n",
      "|    explained_variance   | 0.217       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.44        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    value_loss           | 67.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 380          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035792543 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.575       |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.7         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    value_loss           | 52           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007112439 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.62        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00894    |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004482218 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.563      |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 56.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1d497f0acd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c5ae7",
   "metadata": {},
   "source": [
    "## 4. Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08e21b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('Training', 'Saved Models', 'PPO_Model_Cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39766146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "05540bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2086a475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Saved Models\\\\PPO_Model_Cartpole'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPO_Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "56ced698",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(PPO_Path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e66f7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_23\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 48   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 42   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2c82343dfa0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48401800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26eb99ad",
   "metadata": {},
   "source": [
    "## 5. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78646672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500.0, 0.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1da9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd656a3e",
   "metadata": {},
   "source": [
    "## 6.Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4944409",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m action, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mobs\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'obs' is not defined"
     ]
    }
   ],
   "source": [
    "action, _ = model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fbdd3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:[411.]\n",
      "Episode:2 Score:[500.]\n",
      "Episode:3 Score:[345.]\n",
      "Episode:4 Score:[500.]\n",
      "Episode:5 Score:[500.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "episodes = 5\n",
    "for episode in range(1,episodes +1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render() #Allows us to view the grpahical representaation of environment\n",
    "        action, _ = model.predict(obs) #Now using model.predict\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb569aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391bfa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7675aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ec922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
